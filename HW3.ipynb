{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VdgH3SVvTwV",
        "outputId": "33797e81-536d-45bf-8d7c-68181045a9f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.metrics import edit_distance\n",
        "from nltk.corpus import words\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_d8ZB05wZm6"
      },
      "source": [
        "# ***Regular Expressions***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. time HH:MM pattern in string\n"
      ],
      "metadata": {
        "id": "rjKx4wb1u6Fv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPa5gX_bv_U_",
        "outputId": "da431325-b46f-456f-bfd8-e8275af71c0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['04:59', '17:45']\n"
          ]
        }
      ],
      "source": [
        "def find_time(text):\n",
        "    pattern = r'\\b(?:[01]\\d|2[0-3]):[0-5]\\d\\b'\n",
        "    return re.findall(pattern, text)\n",
        "\n",
        "# test:\n",
        "text = \"this is a correct date: 04:59 and this 17:45, but not 24:00 and 23:60.\"\n",
        "print(find_time(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. handling phone formats, we support below patterns as in text input string\n"
      ],
      "metadata": {
        "id": "Lka7PFOCQiQD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfHUtxZnwFIS",
        "outputId": "4b9eea07-5ae3-4593-a9d1-7edad85eab7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['(04) 999-9999', '03-8888888', '04-777-7777', '036666666', '0544444444', '054-3333333', '(053)2222222', '(054)111-11-11', '(054) 9999999', '0545321456']\n"
          ]
        }
      ],
      "source": [
        "def find_phone_numbers(text):\n",
        "    pattern1 = r'\\b0[1-9]\\d{2}[-\\s]?\\d{3}[-\\s]?\\d{2}[-\\s]?\\d{2}\\b'\n",
        "    pattern2 = r'\\(\\d{1,3}\\)[-.\\s]?\\d{3}[-\\s]?\\d{2}[-\\s]?\\d{2}\\b'\n",
        "    pattern3 = r'\\b\\d{2}[-\\s]?\\d{7}\\b'\n",
        "    pattern4 = r'\\b\\d{3}[-\\s]?\\d{3}[-\\s]?\\d{4}\\b'\n",
        "    pattern5 = r'\\b\\d{2}-\\d{3}-\\d{4}\\b'\n",
        "\n",
        "    return re.findall(pattern1 + '|' + pattern2 + '|' + pattern3 + '|' + pattern4+ '|' + pattern5, text)\n",
        "\n",
        "# test:\n",
        "text = \"(04) 999-9999,03-8888888, 04-777-7777, 036666666,  0544444444, 054-3333333, (053)2222222, (054)111-11-11, (054) 9999999,  0545321456 .\"\n",
        "print(find_phone_numbers(text))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. comments pattern handling"
      ],
      "metadata": {
        "id": "tnzf4HjbRCFP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgjTHAEnwIpV",
        "outputId": "75c5e2eb-75ce-46e3-8c00-c4292af835e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/* This is a first comment */', '/* Another comment */', '/**/']\n"
          ]
        }
      ],
      "source": [
        "def find_comments(text):\n",
        "    pattern = r'/\\*.*?\\*/'\n",
        "    return re.findall(pattern, text)\n",
        "\n",
        "# test:\n",
        "text = \"/* This is a first comment */ Some text comes here /* Another comment */ ...*//**/\"\n",
        "print(find_comments(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. extract number description within 30-40\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4CCsRP_bSuhO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWEhMOl5wMgt",
        "outputId": "431962b0-701e-4193-9a26-73696c447bed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['thirty', 'thirty-one', 'thirty-nine']\n"
          ]
        }
      ],
      "source": [
        "def find_number_descriptions(text):\n",
        "    pattern = r'\\b(thirty(?:-(?:one|two|three|four|five|six|seven|eight|nine))?)(?:\\s|$)\\b'\n",
        "    return re.findall(pattern, text)\n",
        "\n",
        "# Example usage:\n",
        "text = \"I have thirty apples and thirty-one oranges and thirty-blah blah and thirty-nine carrots.\"\n",
        "print(find_number_descriptions(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. date formats handling"
      ],
      "metadata": {
        "id": "OdqJaiFZWEtk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qczn13ZkwPKg",
        "outputId": "964c5731-83a0-46f8-acd2-e8a8ed2e1b4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1990-12-25', '2023-06-15', '2024-02-29', '2016-10-31']\n"
          ]
        }
      ],
      "source": [
        "def find_dates(text):\n",
        "    pattern = r'\\b\\d{4}-(?:(?:0[13578]|1[02])-(?:0[1-9]|1\\d|2[0-9]|3[01])|(?:0[469]|11)-(?:0[1-9]|1\\d|30)|02-(?:0[1-9]|1\\d|2[0-9]))\\b'\n",
        "    return re.findall(pattern, text)\n",
        "\n",
        "# test:\n",
        "text = \"this date is valid: 1990-12-25 and this one 2023-06-15, 2024-02-29 and this 2016-10-31, but not 2016-04-31, 2016-11-31, and 2016-13-33.\"\n",
        "print(find_dates(text))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0hBH8GyxKnJ"
      },
      "source": [
        "#***Similarity between strings***\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PWfT26bbk_SA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"/content/misspellings_and_corrections.txt\"\n",
        "with open(file_name, 'r') as file:\n",
        "    text = file.read()\n",
        "print(text[:500])"
      ],
      "metadata": {
        "id": "h_tYrfoIH1j6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f3ac11e-1560-4fc6-c5b2-daeec1188aa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.\n",
            "NIGEL THRUSH page 48 \n",
            "\n",
            " I have four in my Family Dad Mum and <ERR targ=sister> siter </ERR> .\n",
            "My Dad works at Melton.\n",
            "My <ERR targ=sister> siter </ERR> <ERR targ=goes> go </ERR> to Tonbury.\n",
            "My Mum goes out <ERR targ=sometimes> some times </ERR> .\n",
            "I go to Bridgebrook i go out <ERR targ=sometimes> some times </ERR> on Tuesday night i go to Youth <ERR targ=club> clob </ERR> .\n",
            "On thursday nights I go <ERR targ=bellringing> bell ringing </ERR> on Saturdays I go down to the farm.\n",
            "on sundays I go to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. edit distance value for each error-correction word pair"
      ],
      "metadata": {
        "id": "lCh0S6BaKdko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_edit_distance(incorrect, correction):\n",
        "    return edit_distance(incorrect, correction)\n",
        "\n",
        "def percentage_errors_over_distance(text):\n",
        "    data = []\n",
        "    # finds all error-correction pairs from the text that matches pattern\n",
        "    errors = re.findall(r'<ERR targ=(.*?)>(.*?)</ERR>', text, re.DOTALL)\n",
        "    for targ, words in errors:\n",
        "        correction = words.split(\"</ERR>\")[-1].strip()\n",
        "        distance = calculate_edit_distance( correction, targ)\n",
        "        data.append({'Error': correction, 'Correction': targ, 'Distance': distance})\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "errors_df = percentage_errors_over_distance(text)\n",
        "print(errors_df.head(10))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0AKAtOX__1m",
        "outputId": "5e340ac0-ab75-4914-bbd4-1e4b39d5a8e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Error   Correction  Distance\n",
            "0         siter       sister         1\n",
            "1         siter       sister         1\n",
            "2            go         goes         2\n",
            "3    some times    sometimes         1\n",
            "4    some times    sometimes         1\n",
            "5          clob         club         1\n",
            "6  bell ringing  bellringing         1\n",
            "7          wakh        watch         2\n",
            "8        frount        front         1\n",
            "9        sexeon       second         3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# results validation\n",
        "print(edit_distance(\"sister\", \"siter\"))\n",
        "print(edit_distance(\"goes\", \"go\"))\n",
        "print(edit_distance(\"sexeon\", \"second\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj5VUGhfGYYE",
        "outputId": "3fe86d38-9590-4624-d6ce-62d95566b0fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. error statistics"
      ],
      "metadata": {
        "id": "ErQbwwXCLk_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_errors = len(errors_df)\n",
        "print(f\"Total errors: {total_errors}\")\n",
        "\n",
        "# percentage of errors with edit distance 1 and 2\n",
        "errors_distance_one = errors_df[errors_df['Distance'] == 1]\n",
        "errors_distance_two = errors_df[errors_df['Distance'] == 2]\n",
        "\n",
        "percentage_one = len(errors_distance_one) / total_errors * 100\n",
        "percentage_two = len(errors_distance_two) / total_errors * 100\n",
        "\n",
        "print(f\"Percentage of errors with edit distance 1: {percentage_one}%\")\n",
        "print(f\"Percentage of errors with edit distance 2: {percentage_two}%\")\n",
        "\n",
        "# Print top 10 errors for edit distance 1 and top 10 errors for edit distance 2\n",
        "top_10_errors_distance_one = errors_distance_one['Error'].value_counts().head(10)\n",
        "top_10_errors_distance_two = errors_distance_two['Error'].value_counts().head(10)\n",
        "\n",
        "print(\"\\nTop 10 errors for edit distance 1 (based on error frequency):\")\n",
        "print(top_10_errors_distance_one)\n",
        "\n",
        "print(\"\\nTop 10 errors for edit distance 2 (based on error frequency):\")\n",
        "print(top_10_errors_distance_two)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fkihu6QoLkQ6",
        "outputId": "19d731e6-dbe2-4abe-db37-fcc5a92db1aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total errors: 2600\n",
            "Percentage of errors with edit distance 1: 55.42307692307692%\n",
            "Percentage of errors with edit distance 2: 29.846153846153843%\n",
            "\n",
            "Top 10 errors for edit distance 1 (based on error frequency):\n",
            "to      27\n",
            "Jame    21\n",
            "dont    20\n",
            "two     20\n",
            "here    15\n",
            "the     15\n",
            "go      14\n",
            "is      14\n",
            "of      14\n",
            "its     11\n",
            "Name: Error, dtype: int64\n",
            "\n",
            "Top 10 errors for edit distance 2 (based on error frequency):\n",
            "there    22\n",
            "their    15\n",
            "hear     10\n",
            "no        9\n",
            "vethn     9\n",
            "look      8\n",
            "they      8\n",
            "farm      6\n",
            "lack      6\n",
            "your      6\n",
            "Name: Error, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. list of English words with an edit distance=1 form error word"
      ],
      "metadata": {
        "id": "-appvUv8QYb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_similar_words(error_word):\n",
        "    english_word_set = set(words.words())\n",
        "    error_word_lower = error_word.lower()\n",
        "\n",
        "    # find words with edit distance 1 (error words lower case only)\n",
        "    similar_words = [word for word in english_word_set if edit_distance(error_word_lower, word) == 1]\n",
        "\n",
        "    return similar_words\n",
        "\n",
        "# test:\n",
        "error_word = \"sexeon\"\n",
        "similar_words = find_similar_words(error_word)\n",
        "\n",
        "print(f\"Words with edit distance 1 from '{error_word}':\")\n",
        "print(similar_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKv1dWLdOMiv",
        "outputId": "ed79f724-01e0-4341-e3cb-9f61da894e2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words with edit distance 1 from 'sexeon':\n",
            "['sexton', 'sexern']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. analysis of the first 50 errors"
      ],
      "metadata": {
        "id": "NLfwPpBGR-w3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generates list of similar words proposals based on find_similar_words\n",
        "def generate_proposals_df(errors_df, num_errors=50):\n",
        "    proposals_data = []\n",
        "\n",
        "    for index, row in errors_df.head(num_errors).iterrows():\n",
        "        error_word = row['Error']\n",
        "        correct_word = row['Correction']\n",
        "        proposals = find_similar_words(error_word)\n",
        "        print(f\"Error: '{error_word}', Proposals: '{proposals}'\")\n",
        "        proposals_data.append({'Error': error_word, 'Correct': correct_word, 'Proposals': proposals})\n",
        "\n",
        "    # dataFrame from proposals_data\n",
        "    proposals_df = pd.DataFrame(proposals_data)\n",
        "\n",
        "    return proposals_df\n",
        "# similar words for first 50 words (assumption - we ignore duplicates)\n",
        "proposals_df = generate_proposals_df(errors_df, num_errors=50)"
      ],
      "metadata": {
        "id": "yGjBIJdDSG3h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb0b5ac3-4c35-49ce-dc09-28f4d404057e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 'siter', Proposals: '['titer', 'siver', 'sizer', 'biter', 'site', 'diter', 'sider', 'sifter', 'skiter', 'sixer', 'sitar', 'citer', 'sinter', 'siper', 'sister', 'sier', 'sitter', 'smiter', 'miter', 'niter', 'iter', 'liter']'\n",
            "Error: 'siter', Proposals: '['titer', 'siver', 'sizer', 'biter', 'site', 'diter', 'sider', 'sifter', 'skiter', 'sixer', 'sitar', 'citer', 'sinter', 'siper', 'sister', 'sier', 'sitter', 'smiter', 'miter', 'niter', 'iter', 'liter']'\n",
            "Error: 'go', Proposals: '['geo', 'Po', 'gor', 'goo', 'ago', 'Jo', 'ko', 'Io', 'Mo', 'gos', 'do', 'Ko', 'No', 'Ro', 'got', 'ga', 'ge', 'yo', 'io', 'mo', 'to', 'wo', 'gio', 'goa', 'gob', 'goy', 'gog', 'goi', 'zo', 'god', 'Lo', 'bo', 'g', 'ho', 'Ho', 'gon', 'lo', 'Fo', 'ego', 'gol', 'Ao', 'so', 'o', 'jo', 'no', 'po']'\n",
            "Error: 'some times', Proposals: '['sometimes']'\n",
            "Error: 'some times', Proposals: '['sometimes']'\n",
            "Error: 'clob', Proposals: '['flob', 'lob', 'chob', 'clomb', 'club', 'clod', 'cob', 'cloy', 'clop', 'clog', 'slob', 'blob', 'clot', 'clow']'\n",
            "Error: 'bell ringing', Proposals: '[]'\n",
            "Error: 'wakh', Proposals: '['wash', 'wath', 'wah', 'waky', 'wake', 'wakf', 'rakh', 'waka']'\n",
            "Error: 'frount', Proposals: '['front', 'fount']'\n",
            "Error: 'sexeon', Proposals: '['sexton', 'sexern']'\n",
            "Error: 'wach', Proposals: '['wash', 'wauch', 'wath', 'wack', 'rach', 'watch', 'wah', 'bach', 'wace', 'nach', 'ach', 'tach', 'warch', 'Zach', 'each']'\n",
            "Error: 'wach', Proposals: '['wash', 'wauch', 'wath', 'wack', 'rach', 'watch', 'wah', 'bach', 'wace', 'nach', 'ach', 'tach', 'warch', 'Zach', 'each']'\n",
            "Error: 'cow Boys', Proposals: '[]'\n",
            "Error: 'some times', Proposals: '['sometimes']'\n",
            "Error: 'colbe', Proposals: '['cole']'\n",
            "Error: 'wach', Proposals: '['wash', 'wauch', 'wath', 'wack', 'rach', 'watch', 'wah', 'bach', 'wace', 'nach', 'ach', 'tach', 'warch', 'Zach', 'each']'\n",
            "Error: 'wach', Proposals: '['wash', 'wauch', 'wath', 'wack', 'rach', 'watch', 'wah', 'bach', 'wace', 'nach', 'ach', 'tach', 'warch', 'Zach', 'each']'\n",
            "Error: 'thing', Proposals: '['ting', 'whing', 'hing', 'thin', 'thong', 'thig', 'tying', 'athing', 'ching', 'think', 'thung', 'thine', 'thingy', 'thring']'\n",
            "Error: 'tv', Proposals: '['v', 'ti', 'tav', 'to', 'ta', 'th', 'te', 't', 'tu']'\n",
            "Error: 'squar', Proposals: '['squam', 'quar', 'squat', 'squaw', 'squad', 'squary', 'squab', 'square', 'squark']'\n",
            "Error: 'iyes', Proposals: '['ides', 'yes']'\n",
            "Error: 'oclock', Proposals: '['clock', 'ollock']'\n",
            "Error: 'nock', Proposals: '['jock', 'dock', 'lock', 'bock', 'sock', 'snock', 'nick', 'yock', 'pock', 'rock', 'nook', 'cock', 'neck', 'hock', 'Jock', 'mock', 'ock', 'tock', 'knock']'\n",
            "Error: 'a', Proposals: '['la', 'ya', 'ah', 'al', 'S', 'p', 'F', 'v', 'X', 'N', 'G', 'ad', 'U', 'sa', 'as', 'c', 'b', 'ka', 'da', 'k', 'n', 'y', 'K', 'L', 'Y', 'C', 'ea', 'ar', 'w', 'ba', 'aw', 'H', 'Ma', 'ma', 'am', 'B', 'at', 'd', 'ga', 'ax', 'Q', 'J', 'I', 'm', 'aa', 'l', 'O', 'P', 'Wa', 'z', 'j', 'an', 'q', 's', 'M', 'za', 'T', 'ca', 'f', 'V', 'ak', 'na', 'ta', 'W', 'ai', 'r', 'pa', 'wa', 'fa', 'g', 'Ga', 'ay', 'R', 'D', 'ha', 'e', 'Z', 'ae', 'A', 'ra', 't', 'x', 'i', 'o', 'E', 'u', 'h']'\n",
            "Error: 'oclock', Proposals: '['clock', 'ollock']'\n",
            "Error: 'kild', Proposals: '['kiln', 'mild', 'kilt', 'kilp', 'keld', 'kilo', 'kil', 'kill', 'kind', 'gild', 'wild']'\n",
            "Error: 'see', Proposals: '['gee', 'Ree', 'sen', 'Lee', 'seel', 'seg', 'sew', 'seep', 'ser', 'fee', 'pee', 'seer', 'slee', 'vee', 'smee', 'zee', 'seen', 'sea', 'sec', 'tee', 'skee', 'seed', 'se', 'wee', 'cee', 'usee', 'sey', 'Kee', 'sex', 'seek', 'shee', 'dee', 'lee', 'Gee', 'sere', 'snee', 'sue', 'soe', 'she', 'set', 'yee', 'bee', 'Bee', 'sie', 'ree', 'nee', 'seme', 'seem', 'sye', 'sele']'\n",
            "Error: 'bean', Proposals: '['jean', 'behn', 'mean', 'blan', 'lean', 'beak', 'Jean', 'ben', 'beman', 'benn', 'ean', 'bead', 'beat', 'bejan', 'pean', 'beau', 'yean', 'befan', 'tean', 'Sean', 'been', 'gean', 'beal', 'beany', 'wean', 'dean', 'bran', 'Dean', 'besan', 'beano', 'beam', 'bear', 'ban', 'beant']'\n",
            "Error: 'nock', Proposals: '['jock', 'dock', 'lock', 'bock', 'sock', 'snock', 'nick', 'yock', 'pock', 'rock', 'nook', 'cock', 'neck', 'hock', 'Jock', 'mock', 'ock', 'tock', 'knock']'\n",
            "Error: 'cald', Proposals: '['calx', 'call', 'scald', 'cad', 'cand', 'caid', 'card', 'calp', 'calk', 'bald', 'cal', 'cauld', 'tald', 'calf', 'cold', 'calm', 'calid']'\n",
            "Error: 'cam', Proposals: '['cwm', 'jam', 'ram', 'camb', 'tam', 'aam', 'bam', 'caum', 'cum', 'pam', 'Pam', 'gam', 'dam', 'Jam', 'am', 'cram', 'scam', 'cad', 'cat', 'can', 'yam', 'cab', 'cap', 'Ram', 'caam', 'ca', 'came', 'car', 'cal', 'fam', 'camp', 'Mam', 'sam', 'cay', 'ham', 'oam', 'cham', 'lam', 'cag', 'caw', 'calm', 'Sam', 'nam', 'clam']'\n",
            "Error: 'killd', Proposals: '['kill', 'killy']'\n",
            "Error: 'the', Proposals: '['tue', 'tie', 'tye', 'tae', 'che', 'tha', 'they', 'The', 'thew', 'rhe', 'them', 'tee', 'thee', 'then', 'thy', 'she', 'toe', 'he', 'th', 'tho', 'te', 'tche', 'theb']'\n",
            "Error: 'Here', Proposals: '['there', 'heme', 'dere', 'Sere', 'hele', 'herl', 'herse', 'hare', 'herd', 'her', 'cere', 'mere', 'where', 'hers', 'hern', 'qere', 'ere', 'herb', 'were', 'sere', 'hire', 'yere', 'herem', 'bere', 'hure', 'hero', 'herne']'\n",
            "Error: 'iyes', Proposals: '['ides', 'yes']'\n",
            "Error: 'haveto', Proposals: '[]'\n",
            "Error: 'be for', Proposals: '[]'\n",
            "Error: 'any thing', Proposals: '['anything']'\n",
            "Error: 'als', Proposals: '['al', 'all', 'aly', 'as', 'hals', 'aln', 'aes', 'ala', 'alb', 'alp', 'alms', 'alf', 'also', 'alas', 'alo', 'ass', 'alt', 'alk', 'ale', 'els']'\n",
            "Error: 'weel', Proposals: '['weet', 'seel', 'week', 'peel', 'well', 'heel', 'teel', 'tweel', 'ween', 'eel', 'weal', 'jeel', 'wee', 'aweel', 'wheel', 'weep', 'yeel', 'keel', 'reel', 'feel', 'weed']'\n",
            "Error: 'weel', Proposals: '['weet', 'seel', 'week', 'peel', 'well', 'heel', 'teel', 'tweel', 'ween', 'eel', 'weal', 'jeel', 'wee', 'aweel', 'wheel', 'weep', 'yeel', 'keel', 'reel', 'feel', 'weed']'\n",
            "Error: 'sally', Proposals: '['sully', 'Sally', 'tally', 'smally', 'soally', 'selly', 'bally', 'saily', 'sadly', 'wally', 'salty', 'pally', 'sably', 'ally', 'salle', 'salay', 'salvy', 'fally', 'silly', 'rally', 'saltly', 'gally', 'dally']'\n",
            "Error: 'other', Proposals: '['ocher', 'pother', 'otter', 'nother', 'rother', 'bother', 'ither', 'tother', 'fother', 'outher', 'mother', 'ether']'\n",
            "Error: 'rouns', Proposals: '['roun', 'round']'\n",
            "Error: 'don', Proposals: '['din', 'Jon', 'domn', 'Hon', 'Mon', 'mon', 'dorn', 'dop', 'on', 'dob', 'non', 'dont', 'pon', 'dos', 'yon', 'do', 'con', 'done', 'doon', 'Bon', 'bon', 'Ron', 'dong', 'dor', 'dom', 'eon', 'dod', 'den', 'kon', 'dan', 'doc', 'ion', 'Fon', 'dot', 'Don', 'Son', 'dow', 'gon', 'won', 'dog', 'dun', 'down', 'doe', 'son', 'ton']'\n",
            "Error: 'rings', Proposals: '['ring', 'ringe', 'ringy']'\n",
            "Error: 'we', Proposals: '['ce', 'wye', 'awe', 'wen', 'wi', 'ewe', 'wet', 'w', 'Ewe', 'Ge', 'be', 're', 'wy', 'oe', 'ge', 'ye', 'web', 'se', 'wee', 'wo', 'wey', 'fe', 'ne', 'wem', 'woe', 'de', 'me', 'owe', 'wa', 'he', 'wed', 'e', 'ae', 'te', 'wae', 'wer', 'ie']'\n",
            "Error: 'brakes', Proposals: '['braces', 'brake', 'braker']'\n",
            "Error: 'carfull', Proposals: '['carful']'\n",
            "Error: 'Cynthia', Proposals: '['Cynthia']'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# average number of proposals\n",
        "average_proposals = proposals_df['Proposals'].apply(len).mean()\n",
        "print(f\"Average number of proposals: {average_proposals}\")\n",
        "\n",
        "def calculate_percentage_correct_in_proposals(proposals_df):\n",
        "    total_cases = len(proposals_df)\n",
        "    correct_in_proposals = sum(proposals_df['Correct'].isin(proposals_df['Proposals']))\n",
        "    percentage = (correct_in_proposals / total_cases) * 100\n",
        "    return percentage\n",
        "\n",
        "# calculate percentage of correct words on proposals\n",
        "percentage_correct = calculate_percentage_correct_in_proposals(proposals_df)\n",
        "print(f\"Percentage of cases where the correct word is among the proposals list: {percentage_correct:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFXEU9xMfGqs",
        "outputId": "a6bee8e9-ddaa-4e5e-f106-552b2f3468ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average number of proposals: 14.86\n",
            "Percentage of cases where the correct word is among the proposals list: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_cases_correct_not_in_proposals(proposals_df):\n",
        "    incorrect_cases = proposals_df[~proposals_df['Correct'].isin(proposals_df['Proposals'])]\n",
        "\n",
        "    print(\"Cases where correct word isn't among the proposals:\")\n",
        "    print(incorrect_cases)\n",
        "\n",
        "# Assuming you have the proposals_df DataFrame\n",
        "check_cases_correct_not_in_proposals(proposals_df)\n"
      ],
      "metadata": {
        "id": "ZX_wMlJ6PZR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# A. Prepare the training data\n",
        "train_data = fetch_20newsgroups(subset='train')\n",
        "train_documents = train_data.data\n",
        "train_labels = train_data.target\n",
        "\n",
        "# B. Prepare the test data\n",
        "test_data = fetch_20newsgroups(subset='test')\n",
        "test_documents = test_data.data\n",
        "test_labels = test_data.target\n",
        "\n",
        "# C. Choose representation methods (TF and TF-IDF) and similarity measures (dot-product and cosine similarity)\n",
        "# C.1 TF representation\n",
        "tf_vectorizer = CountVectorizer()\n",
        "train_tf_matrix = tf_vectorizer.fit_transform(train_documents)\n",
        "test_tf_matrix = tf_vectorizer.transform(test_documents)\n",
        "\n",
        "# C.2 TF-IDF representation\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "train_tfidf_matrix = tfidf_vectorizer.fit_transform(train_documents)\n",
        "test_tfidf_matrix = tfidf_vectorizer.transform(test_documents)\n",
        "\n",
        "# D. Define a function to predict using KNN\n",
        "def knn_predict(train_matrix, test_matrix, k, similarity_measure):\n",
        "    predictions = []\n",
        "\n",
        "    for test_doc in test_matrix:\n",
        "        if similarity_measure == 'dot_product':\n",
        "            similarities = np.dot(train_matrix, test_doc.T)\n",
        "        elif similarity_measure == 'cosine_similarity':\n",
        "            similarities = pairwise_distances(train_matrix, test_doc, metric='cosine').flatten()\n",
        "\n",
        "        # Find the indices of the k most similar training examples\n",
        "        nearest_indices = np.argsort(similarities)[:k]\n",
        "        # Predict the label based on the majority class among the k nearest neighbors\n",
        "        predicted_label = np.argmax(np.bincount(train_labels[nearest_indices]))\n",
        "        predictions.append(predicted_label)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# E. Evaluate the model for each combination of representation method and similarity measure\n",
        "methods = [('TF', train_tf_matrix, test_tf_matrix), ('TF-IDF', train_tfidf_matrix, test_tfidf_matrix)]\n",
        "similarity_measures = ['dot_product', 'cosine_similarity']\n",
        "\n",
        "for method_name, train_matrix, test_matrix in methods:\n",
        "    for similarity_measure in similarity_measures:\n",
        "        k = 1  # 1-NN\n",
        "        predictions = knn_predict(train_matrix, test_matrix, k, similarity_measure)\n",
        "\n",
        "        # Calculate accuracy and print the results\n",
        "        accuracy = accuracy_score(test_labels, predictions)\n",
        "        print(f'{method_name} representation with {similarity_measure}: Accuracy = {accuracy:.4f}')"
      ],
      "metadata": {
        "id": "aE5OTMpwGhD8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}